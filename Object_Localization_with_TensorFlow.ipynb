{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Object Localization with TensorFlow\r\n"
   ],
   "metadata": {
    "id": "mfJ15yGqjM1z"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 2: Download and Visualize Data"
   ],
   "metadata": {
    "id": "4eWHR2O5j2g0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!wget https://github.com/hfg-gmuend/openmoji/releases/latest/download/openmoji-72x72-color.zip\r\n",
    "!mkdir emojis\r\n",
    "!unzip -q openmoji-72x72-color.zip -d ./emojis\r\n",
    "!pip install -q tensorflow==2.4"
   ],
   "outputs": [],
   "metadata": {
    "id": "UsuZWoD6cvYt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib inline\r\n",
    "\r\n",
    "import tensorflow as tf\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import os\r\n",
    "\r\n",
    "from PIL import Image, ImageDraw\r\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, BatchNormalization, Dropout\r\n",
    "\r\n",
    "print('Check if using TensorFlow 2.4')\r\n",
    "print('Using TensorFlow version', tf.__version__)"
   ],
   "outputs": [],
   "metadata": {
    "id": "PsBFzZWNxnFN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emojis = {\r\n",
    "    0: {'name': 'happy', 'file': '1F642.png'},\r\n",
    "    1: {'name': 'laughing', 'file': '1F602.png'},\r\n",
    "    2: {'name': 'skeptical', 'file': '1F928.png'},\r\n",
    "    3: {'name': 'sad', 'file': '1F630.png'},\r\n",
    "    4: {'name': 'cool', 'file': '1F60E.png'},\r\n",
    "    5: {'name': 'whoa', 'file': '1F62F.png'},\r\n",
    "    6: {'name': 'crying', 'file': '1F62D.png'},\r\n",
    "    7: {'name': 'puking', 'file': '1F92E.png'},\r\n",
    "    8: {'name': 'nervous', 'file': '1F62C.png'}\r\n",
    "}\r\n",
    "\r\n",
    "plt.figure(figsize=(9, 9))\r\n",
    "\r\n",
    "for i, (j, e) in enumerate(emojis.items()):\r\n",
    "    plt.subplot(3, 3, i + 1)\r\n",
    "    plt.imshow(plt.imread(os.path.join('emojis', e['file'])))\r\n",
    "    plt.xlabel(e['name'])\r\n",
    "    plt.xticks([])\r\n",
    "    plt.yticks([])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "9_cD7ll7gAnD"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3: Create Examples"
   ],
   "metadata": {
    "id": "C0gSTjKDkJ9y"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for class_id, values in emojis.items():\r\n",
    "    png_file = Image.open(os.path.join('emojis', values['file'])).convert('RGBA')\r\n",
    "    png_file.load()\r\n",
    "    new_file = Image.new(\"RGB\", png_file.size, (255, 255, 255))\r\n",
    "    new_file.paste(png_file, mask=png_file.split()[3])\r\n",
    "    emojis[class_id]['image'] = new_file"
   ],
   "outputs": [],
   "metadata": {
    "id": "rn91bMsseWJu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "emojis"
   ],
   "outputs": [],
   "metadata": {
    "id": "bBZgOVsUke6o"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def create_example():\r\n",
    "  class_id = np.random.randint(0, 9)\r\n",
    "  image = np.ones((144, 144, 3)) * 255\r\n",
    "  row = np.random.randint(0, 72)\r\n",
    "  col = np.random.randint(0, 72)\r\n",
    "  image[row: row + 72, col: col + 72, :] = np.array(emojis[class_id]['image'])\r\n",
    "  return image.astype('uint8'), class_id, (row + 10) / 144, (col + 10) / 144"
   ],
   "outputs": [],
   "metadata": {
    "id": "8xz9sL75lFLW"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image, class_id, row, col = create_example()\r\n",
    "plt.imshow(image);"
   ],
   "outputs": [],
   "metadata": {
    "id": "yyV_mNaQphLd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 4: Plot Bounding Boxes"
   ],
   "metadata": {
    "id": "yAriAzdGkO49"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_bounding_box(image, gt_coords, pred_coords=[], norm=False):\r\n",
    "  if norm:\r\n",
    "    image *= 255.\r\n",
    "    image = image.astype('uint8')\r\n",
    "  image = Image.fromarray(image)\r\n",
    "  draw = ImageDraw.Draw(image)\r\n",
    "\r\n",
    "  row, col = gt_coords\r\n",
    "  row *= 144\r\n",
    "  col *= 144\r\n",
    "  draw.rectangle((col, row, col + 52, row + 52), outline='green', width=3)\r\n",
    "\r\n",
    "  if len(pred_coords) == 2:\r\n",
    "    row, col = pred_coords\r\n",
    "    row *= 144\r\n",
    "    col *= 144\r\n",
    "    draw.rectangle((col, row, col + 52, row + 52), outline='red', width=3)\r\n",
    "  return image"
   ],
   "outputs": [],
   "metadata": {
    "id": "TSSY93pHm1Z5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image = plot_bounding_box(image, gt_coords=[row, col])\r\n",
    "plt.imshow(image)\r\n",
    "plt.title(emojis[class_id]['name'])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "01TUfno0mTQv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 5: Data Generator"
   ],
   "metadata": {
    "id": "dHiS285zkSNK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def data_generator(batch_size=16):\r\n",
    "  while True:\r\n",
    "    x_batch = np.zeros((batch_size, 144, 144, 3))\r\n",
    "    y_batch = np.zeros((batch_size, 9))\r\n",
    "    bbox_batch = np.zeros((batch_size, 2))\r\n",
    "\r\n",
    "    for i in range(0, batch_size):\r\n",
    "      image, class_id, row, col = create_example()\r\n",
    "      x_batch[i] = image / 255.\r\n",
    "      y_batch[i, class_id] = 1.0\r\n",
    "      bbox_batch[i] = np.array([row, col])\r\n",
    "    yield {'image': x_batch}, {'class_out': y_batch, 'box_out': bbox_batch}"
   ],
   "outputs": [],
   "metadata": {
    "id": "gR5AYygBqAVH"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "example, label = next(data_generator(1))\r\n",
    "image = example['image'][0]\r\n",
    "class_id = np.argmax(label['class_out'][0])\r\n",
    "coords = label['box_out'][0]\r\n",
    "\r\n",
    "image = plot_bounding_box(image, coords, norm=True)\r\n",
    "plt.imshow(image)\r\n",
    "plt.title(emojis[class_id]['name'])\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "fY3pM-O5sS0H"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 6: Model"
   ],
   "metadata": {
    "id": "JIfAVFDGkVAT"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "input_ = Input(shape=(144, 144, 3), name='image')\r\n",
    "\r\n",
    "x = input_\r\n",
    "\r\n",
    "for i in range(0, 5):\r\n",
    "  n_filters = 2**(4 + i)\r\n",
    "  x = Conv2D(n_filters, 3, activation='relu')(x)\r\n",
    "  x = BatchNormalization()(x)\r\n",
    "  x = MaxPool2D(2)(x)\r\n",
    "\r\n",
    "x = Flatten()(x)\r\n",
    "x = Dense(256, activation='relu')(x)\r\n",
    "\r\n",
    "class_out = Dense(9, activation='softmax', name='class_out')(x)\r\n",
    "box_out = Dense(2, name='box_out')(x)\r\n",
    "\r\n",
    "model = tf.keras.models.Model(input_, [class_out, box_out])\r\n",
    "model.summary()"
   ],
   "outputs": [],
   "metadata": {
    "id": "jahKrZ9yspGi"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 7: Custom Metric: IoU"
   ],
   "metadata": {
    "id": "287Mj5b8kZ_t"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class IoU(tf.keras.metrics.Metric):\r\n",
    "  def __init__(self, **kwargs):\r\n",
    "    super(IoU, self).__init__(**kwargs)\r\n",
    "\r\n",
    "    self.iou = self.add_weight(name='iou', initializer='zeros')\r\n",
    "    self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\r\n",
    "    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')\r\n",
    "  \r\n",
    "  def update_state(self, y_true, y_pred, sample_weight=None):\r\n",
    "    def get_box(y):\r\n",
    "      rows, cols = y[:, 0], y[:, 1]\r\n",
    "      rows, cols = rows * 144, cols * 144\r\n",
    "      y1, y2 = rows, rows + 52\r\n",
    "      x1, x2 = cols, cols + 52\r\n",
    "      return x1, y1, x2, y2\r\n",
    "    \r\n",
    "    def get_area(x1, y1, x2, y2):\r\n",
    "      return tf.math.abs(x2 - x1) * tf.math.abs(y2 - y1)\r\n",
    "    \r\n",
    "    gt_x1, gt_y1, gt_x2, gt_y2 = get_box(y_true)\r\n",
    "    p_x1, p_y1, p_x2, p_y2 = get_box(y_pred)\r\n",
    "\r\n",
    "    i_x1 = tf.maximum(gt_x1, p_x1)\r\n",
    "    i_y1 = tf.maximum(gt_y1, p_y1)\r\n",
    "    i_x2 = tf.minimum(gt_x2, p_x2)\r\n",
    "    i_y2 = tf.minimum(gt_y2, p_y2)\r\n",
    "\r\n",
    "    i_area = get_area(i_x1, i_y1, i_x2, i_y2)\r\n",
    "    u_area = get_area(gt_x1, gt_y1, gt_x2, gt_y2) + get_area(p_x1, p_y1, p_x2, p_y2) - i_area\r\n",
    "\r\n",
    "    iou = tf.math.divide(i_area, u_area)\r\n",
    "    self.num_ex.assign_add(1)\r\n",
    "    self.total_iou.assign_add(tf.reduce_mean(iou))\r\n",
    "    self.iou = tf.math.divide(self.total_iou, self.num_ex)\r\n",
    "  \r\n",
    "  def result(self):\r\n",
    "    return self.iou\r\n",
    "  \r\n",
    "  def reset_state(self):\r\n",
    "    self.iou = self.add_weight(name='iou', initializer='zeros')\r\n",
    "    self.total_iou = self.add_weight(name='total_iou', initializer='zeros')\r\n",
    "    self.num_ex = self.add_weight(name='num_ex', initializer='zeros')\r\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "608R_-1V9QCh"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 8: Compile the Model"
   ],
   "metadata": {
    "id": "Q9Qzo_RpNFaM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.compile(\r\n",
    "    loss={\r\n",
    "        'class_out': 'categorical_crossentropy',\r\n",
    "        'box_out': 'mse'\r\n",
    "    },\r\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\r\n",
    "    metrics={\r\n",
    "        'class_out': 'accuracy',\r\n",
    "        'box_out': IoU(name='iou')\r\n",
    "    }\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "id": "jl4KzYM9NEb4"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 9: Custom Callback: Model Testing"
   ],
   "metadata": {
    "id": "TgorrihHLZox"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_model(model, test_datagen):\r\n",
    "  example, label = next(test_datagen)\r\n",
    "  x = example['image']\r\n",
    "  y = label['class_out']\r\n",
    "  box = label['box_out']\r\n",
    "\r\n",
    "  pred_y, pred_box = model.predict(x)\r\n",
    "\r\n",
    "  pred_coords = pred_box[0]\r\n",
    "  gt_coords = box[0]\r\n",
    "  pred_class = np.argmax(pred_y[0])\r\n",
    "  image = x[0]\r\n",
    "\r\n",
    "  gt = emojis[np.argmax(y[0])]['name']\r\n",
    "  pred_class_name = emojis[pred_class]['name']\r\n",
    "\r\n",
    "  image = plot_bounding_box(image, gt_coords, pred_coords, norm=True)\r\n",
    "  color = 'green' if gt == pred_class_name else 'red'\r\n",
    "\r\n",
    "  plt.imshow(image)\r\n",
    "  plt.xlabel(f'Pred: {pred_class_name}', color=color)\r\n",
    "  plt.ylabel(f'GT: {gt}', color=color)\r\n",
    "  plt.xticks([])\r\n",
    "  plt.yticks([])"
   ],
   "outputs": [],
   "metadata": {
    "id": "Di5DItY5vuu1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test(model):\r\n",
    "  test_datagen = data_generator(1)\r\n",
    "\r\n",
    "  plt.figure(figsize=(16, 4))\r\n",
    "\r\n",
    "  for i in range(0, 6):\r\n",
    "    plt.subplot(1, 6, i + 1)\r\n",
    "    test_model(model, test_datagen)\r\n",
    "  plt.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "xR3C5zQ_LZox"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test(model)"
   ],
   "outputs": [],
   "metadata": {
    "id": "_9UgYrTILZox"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ShowTestImages(tf.keras.callbacks.Callback):\r\n",
    "  def on_epoch_end(self, epoch, logs=None):\r\n",
    "    test(self.model)"
   ],
   "outputs": [],
   "metadata": {
    "id": "v-A8DZ4zxQlZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 10: Model Training"
   ],
   "metadata": {
    "id": "lvaxZOzOkgDN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def lr_schedule(epoch, lr):\r\n",
    "  if (epoch + 1) % 5 == 0:\r\n",
    "    lr *= 0.2\r\n",
    "  return max(lr, 3e-7)\r\n",
    "\r\n",
    "\r\n",
    "_ = model.fit(\r\n",
    "    data_generator(),\r\n",
    "    epochs=50,\r\n",
    "    steps_per_epoch=500,\r\n",
    "    callbacks=[\r\n",
    "               ShowTestImages(),\r\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='box_out_iou', patience=3, mode='max'),\r\n",
    "               tf.keras.callbacks.LearningRateScheduler(lr_schedule)\r\n",
    "    ]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {
    "id": "WfMjSE41ugR7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {
    "id": "vRDTeZT_mSAo"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Object Localization with TensorFlow - Starter.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}